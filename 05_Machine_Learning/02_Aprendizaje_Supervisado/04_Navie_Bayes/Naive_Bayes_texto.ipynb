{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "noticias=pd.read_csv(\"./Datos/noticias.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descripcion</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aunque parezca mentira, las emisiones de dióxi...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubo un proyecto impulsado por la Unión Europe...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China ha confirmado la conclusión con éxito de...</td>\n",
       "      <td>tecnología</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En su fructífera carrera como humorista, actor...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tras dos años de negociación entre la instituc...</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         descripcion   categoria\n",
       "0  Aunque parezca mentira, las emisiones de dióxi...     cultura\n",
       "1  Hubo un proyecto impulsado por la Unión Europe...     cultura\n",
       "2  China ha confirmado la conclusión con éxito de...  tecnología\n",
       "3  En su fructífera carrera como humorista, actor...     cultura\n",
       "4  Tras dos años de negociación entre la instituc...     cultura"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cultura       54.568051\n",
       "tecnología    25.450136\n",
       "ocio          19.981813\n",
       "Name: categoria, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias[\"categoria\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdecode_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstrip_accents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpreprocessor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtoken_pattern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'(?u)\\\\b\\\\w\\\\w+\\\\b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[1;34m'numpy.float64'\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0muse_idf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msmooth_idf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msublinear_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Convert a collection of raw documents to a matrix of TF-IDF features.\n",
      "\n",
      "Equivalent to :class:`CountVectorizer` followed by\n",
      ":class:`TfidfTransformer`.\n",
      "\n",
      "Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "input : {'filename', 'file', 'content'}, default='content'\n",
      "    - If `'filename'`, the sequence passed as an argument to fit is\n",
      "      expected to be a list of filenames that need reading to fetch\n",
      "      the raw content to analyze.\n",
      "\n",
      "    - If `'file'`, the sequence items must have a 'read' method (file-like\n",
      "      object) that is called to fetch the bytes in memory.\n",
      "\n",
      "    - If `'content'`, the input is expected to be a sequence of items that\n",
      "      can be of type string or byte.\n",
      "\n",
      "encoding : str, default='utf-8'\n",
      "    If bytes or files are given to analyze, this encoding is used to\n",
      "    decode.\n",
      "\n",
      "decode_error : {'strict', 'ignore', 'replace'}, default='strict'\n",
      "    Instruction on what to do if a byte sequence is given to analyze that\n",
      "    contains characters not of the given `encoding`. By default, it is\n",
      "    'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
      "    values are 'ignore' and 'replace'.\n",
      "\n",
      "strip_accents : {'ascii', 'unicode'}, default=None\n",
      "    Remove accents and perform other character normalization\n",
      "    during the preprocessing step.\n",
      "    'ascii' is a fast method that only works on characters that have\n",
      "    an direct ASCII mapping.\n",
      "    'unicode' is a slightly slower method that works on any characters.\n",
      "    None (default) does nothing.\n",
      "\n",
      "    Both 'ascii' and 'unicode' use NFKD normalization from\n",
      "    :func:`unicodedata.normalize`.\n",
      "\n",
      "lowercase : bool, default=True\n",
      "    Convert all characters to lowercase before tokenizing.\n",
      "\n",
      "preprocessor : callable, default=None\n",
      "    Override the preprocessing (string transformation) stage while\n",
      "    preserving the tokenizing and n-grams generation steps.\n",
      "    Only applies if ``analyzer`` is not callable.\n",
      "\n",
      "tokenizer : callable, default=None\n",
      "    Override the string tokenization step while preserving the\n",
      "    preprocessing and n-grams generation steps.\n",
      "    Only applies if ``analyzer == 'word'``.\n",
      "\n",
      "analyzer : {'word', 'char', 'char_wb'} or callable, default='word'\n",
      "    Whether the feature should be made of word or character n-grams.\n",
      "    Option 'char_wb' creates character n-grams only from text inside\n",
      "    word boundaries; n-grams at the edges of words are padded with space.\n",
      "\n",
      "    If a callable is passed it is used to extract the sequence of features\n",
      "    out of the raw, unprocessed input.\n",
      "\n",
      "    .. versionchanged:: 0.21\n",
      "        Since v0.21, if ``input`` is ``'filename'`` or ``'file'``, the data\n",
      "        is first read from the file and then passed to the given callable\n",
      "        analyzer.\n",
      "\n",
      "stop_words : {'english'}, list, default=None\n",
      "    If a string, it is passed to _check_stop_list and the appropriate stop\n",
      "    list is returned. 'english' is currently the only supported string\n",
      "    value.\n",
      "    There are several known issues with 'english' and you should\n",
      "    consider an alternative (see :ref:`stop_words`).\n",
      "\n",
      "    If a list, that list is assumed to contain stop words, all of which\n",
      "    will be removed from the resulting tokens.\n",
      "    Only applies if ``analyzer == 'word'``.\n",
      "\n",
      "    If None, no stop words will be used. max_df can be set to a value\n",
      "    in the range [0.7, 1.0) to automatically detect and filter stop\n",
      "    words based on intra corpus document frequency of terms.\n",
      "\n",
      "token_pattern : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\"\n",
      "    Regular expression denoting what constitutes a \"token\", only used\n",
      "    if ``analyzer == 'word'``. The default regexp selects tokens of 2\n",
      "    or more alphanumeric characters (punctuation is completely ignored\n",
      "    and always treated as a token separator).\n",
      "\n",
      "    If there is a capturing group in token_pattern then the\n",
      "    captured group content, not the entire match, becomes the token.\n",
      "    At most one capturing group is permitted.\n",
      "\n",
      "ngram_range : tuple (min_n, max_n), default=(1, 1)\n",
      "    The lower and upper boundary of the range of n-values for different\n",
      "    n-grams to be extracted. All values of n such that min_n <= n <= max_n\n",
      "    will be used. For example an ``ngram_range`` of ``(1, 1)`` means only\n",
      "    unigrams, ``(1, 2)`` means unigrams and bigrams, and ``(2, 2)`` means\n",
      "    only bigrams.\n",
      "    Only applies if ``analyzer`` is not callable.\n",
      "\n",
      "max_df : float or int, default=1.0\n",
      "    When building the vocabulary ignore terms that have a document\n",
      "    frequency strictly higher than the given threshold (corpus-specific\n",
      "    stop words).\n",
      "    If float in range [0.0, 1.0], the parameter represents a proportion of\n",
      "    documents, integer absolute counts.\n",
      "    This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "min_df : float or int, default=1\n",
      "    When building the vocabulary ignore terms that have a document\n",
      "    frequency strictly lower than the given threshold. This value is also\n",
      "    called cut-off in the literature.\n",
      "    If float in range of [0.0, 1.0], the parameter represents a proportion\n",
      "    of documents, integer absolute counts.\n",
      "    This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "max_features : int, default=None\n",
      "    If not None, build a vocabulary that only consider the top\n",
      "    max_features ordered by term frequency across the corpus.\n",
      "\n",
      "    This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "vocabulary : Mapping or iterable, default=None\n",
      "    Either a Mapping (e.g., a dict) where keys are terms and values are\n",
      "    indices in the feature matrix, or an iterable over terms. If not\n",
      "    given, a vocabulary is determined from the input documents.\n",
      "\n",
      "binary : bool, default=False\n",
      "    If True, all non-zero term counts are set to 1. This does not mean\n",
      "    outputs will have only 0/1 values, only that the tf term in tf-idf\n",
      "    is binary. (Set idf and normalization to False to get 0/1 outputs).\n",
      "\n",
      "dtype : dtype, default=float64\n",
      "    Type of the matrix returned by fit_transform() or transform().\n",
      "\n",
      "norm : {'l1', 'l2'}, default='l2'\n",
      "    Each output row will have unit norm, either:\n",
      "\n",
      "    - 'l2': Sum of squares of vector elements is 1. The cosine\n",
      "      similarity between two vectors is their dot product when l2 norm has\n",
      "      been applied.\n",
      "    - 'l1': Sum of absolute values of vector elements is 1.\n",
      "      See :func:`preprocessing.normalize`.\n",
      "\n",
      "use_idf : bool, default=True\n",
      "    Enable inverse-document-frequency reweighting. If False, idf(t) = 1.\n",
      "\n",
      "smooth_idf : bool, default=True\n",
      "    Smooth idf weights by adding one to document frequencies, as if an\n",
      "    extra document was seen containing every term in the collection\n",
      "    exactly once. Prevents zero divisions.\n",
      "\n",
      "sublinear_tf : bool, default=False\n",
      "    Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "vocabulary_ : dict\n",
      "    A mapping of terms to feature indices.\n",
      "\n",
      "fixed_vocabulary_ : bool\n",
      "    True if a fixed vocabulary of term to indices mapping\n",
      "    is provided by the user.\n",
      "\n",
      "idf_ : array of shape (n_features,)\n",
      "    The inverse document frequency (IDF) vector; only defined\n",
      "    if ``use_idf`` is True.\n",
      "\n",
      "stop_words_ : set\n",
      "    Terms that were ignored because they either:\n",
      "\n",
      "      - occurred in too many documents (`max_df`)\n",
      "      - occurred in too few documents (`min_df`)\n",
      "      - were cut off by feature selection (`max_features`).\n",
      "\n",
      "    This is only available if no vocabulary was given.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "CountVectorizer : Transforms text into a sparse matrix of n-gram counts.\n",
      "\n",
      "TfidfTransformer : Performs the TF-IDF transformation from a provided\n",
      "    matrix of counts.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The ``stop_words_`` attribute can get large and increase the model size\n",
      "when pickling. This attribute is provided only for introspection and can\n",
      "be safely removed using delattr or set to None before pickling.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
      ">>> corpus = [\n",
      "...     'This is the first document.',\n",
      "...     'This document is the second document.',\n",
      "...     'And this is the third one.',\n",
      "...     'Is this the first document?',\n",
      "... ]\n",
      ">>> vectorizer = TfidfVectorizer()\n",
      ">>> X = vectorizer.fit_transform(corpus)\n",
      ">>> vectorizer.get_feature_names_out()\n",
      "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
      "       'this'], ...)\n",
      ">>> print(X.shape)\n",
      "(4, 9)\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\daniel montes\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "TfidfVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Datos/stopwords-es.json\") as texto:\n",
    "    palabras=json.load(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '_',\n",
       " 'a',\n",
       " 'actualmente',\n",
       " 'acuerdo',\n",
       " 'adelante',\n",
       " 'ademas',\n",
       " 'además',\n",
       " 'adrede',\n",
       " 'afirmó',\n",
       " 'agregó',\n",
       " 'ahi',\n",
       " 'ahora',\n",
       " 'ahí',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'alguna',\n",
       " 'algunas',\n",
       " 'alguno',\n",
       " 'algunos',\n",
       " 'algún']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eliminar los acentos\n",
    "vectorizador=TfidfVectorizer(strip_accents=\"unicode\",stop_words=palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16495, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel Montes\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afirmo', 'agrego', 'algun', 'anadio', 'aseguro', 'comento', 'considero', 'dejo', 'demas', 'estabamos', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'explico', 'expreso', 'fueramos', 'fuesemos', 'habeis', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'indico', 'llego', 'manifesto', 'menciono', 'ningun', 'podra', 'podran', 'proximos', 'quedo', 'realizo', 'seais', 'senalo', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'traves', 'tuvieramos', 'tuviesemos', 'ultima', 'ultimas', 'ultimos'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<16495x59952 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 397698 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador.fit_transform(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=vectorizador.fit_transform(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_df=pd.DataFrame(DF.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias_df[\"target\"]=noticias[\"categoria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59943</th>\n",
       "      <th>59944</th>\n",
       "      <th>59945</th>\n",
       "      <th>59946</th>\n",
       "      <th>59947</th>\n",
       "      <th>59948</th>\n",
       "      <th>59949</th>\n",
       "      <th>59950</th>\n",
       "      <th>59951</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tecnología</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cultura</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59953 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  59943  59944  59945  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "\n",
       "   59946  59947  59948  59949  59950  59951      target  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0     cultura  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0     cultura  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0  tecnología  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0     cultura  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0     cultura  \n",
       "\n",
       "[5 rows x 59953 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.37 GiB for an array with shape (16495, 59952) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mf:\\The Bridge\\Bootcamp_Abril_2023\\Bootcamp_Abril2023\\05_Machine_Learning\\02_Aprendizaje_Supervisado\\04_Navie_Bayes\\Naive_Bayes_texto.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/The%20Bridge/Bootcamp_Abril_2023/Bootcamp_Abril2023/05_Machine_Learning/02_Aprendizaje_Supervisado/04_Navie_Bayes/Naive_Bayes_texto.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X\u001b[39m=\u001b[39mnoticias_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/The%20Bridge/Bootcamp_Abril_2023/Bootcamp_Abril2023/05_Machine_Learning/02_Aprendizaje_Supervisado/04_Navie_Bayes/Naive_Bayes_texto.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y\u001b[39m=\u001b[39mnoticias_df[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/The%20Bridge/Bootcamp_Abril_2023/Bootcamp_Abril2023/05_Machine_Learning/02_Aprendizaje_Supervisado/04_Navie_Bayes/Naive_Bayes_texto.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_train,X_test,y_train,y_test\u001b[39m=\u001b[39mtrain_test_split(DF\u001b[39m.\u001b[39;49mtoarray(),y,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/The%20Bridge/Bootcamp_Abril_2023/Bootcamp_Abril2023/05_Machine_Learning/02_Aprendizaje_Supervisado/04_Navie_Bayes/Naive_Bayes_texto.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                                train_size\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/The%20Bridge/Bootcamp_Abril_2023/Bootcamp_Abril2023/05_Machine_Learning/02_Aprendizaje_Supervisado/04_Navie_Bayes/Naive_Bayes_texto.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                                random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/The%20Bridge/Bootcamp_Abril_2023/Bootcamp_Abril2023/05_Machine_Learning/02_Aprendizaje_Supervisado/04_Navie_Bayes/Naive_Bayes_texto.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                               shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel Montes\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:1039\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39m'\u001b[39m\u001b[39mcf\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1039\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_toarray_args(order, out)\n\u001b[0;32m   1040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous):\n\u001b[0;32m   1041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOutput array must be C or F contiguous\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel Montes\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:1202\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   1201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1202\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mzeros(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.37 GiB for an array with shape (16495, 59952) and data type float64"
     ]
    }
   ],
   "source": [
    "# X=noticias_df.drop(columns=\"target\")\n",
    "# y=noticias_df[\"target\"]\n",
    "# X_train,X_test,y_train,y_test=train_test_split(DF.toarray(),y,\n",
    "#                                                train_size=0.7,\n",
    "#                                                random_state=42,\n",
    "#                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=Modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opcion de Bernouilli\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizador_cuenta=CountVectorizer(stop_words=palabras,\n",
    "                                    binary=True,\n",
    "                                    strip_accents=\"unicode\",\n",
    "                                    max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador_cuenta.fit(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tierra': 929,\n",
       " 'verde': 969,\n",
       " '30': 25,\n",
       " 'anos': 76,\n",
       " 'epoca': 335,\n",
       " 'principal': 767,\n",
       " 'estudio': 365,\n",
       " 'internacional': 500,\n",
       " 'publicado': 796,\n",
       " 'pasar': 708,\n",
       " 'proyecto': 789,\n",
       " 'union': 950,\n",
       " 'europea': 369,\n",
       " 'metodo': 598,\n",
       " 'lengua': 527,\n",
       " 'espanol': 347,\n",
       " 'sistema': 882,\n",
       " 'espanoles': 349,\n",
       " 'puedan': 802,\n",
       " 'entender': 330,\n",
       " 'china': 166,\n",
       " 'confirmado': 204,\n",
       " 'exito': 377,\n",
       " 'forma': 402,\n",
       " 'totalmente': 935,\n",
       " 'robot': 845,\n",
       " 'logro': 552,\n",
       " 'personal': 725,\n",
       " 'humano': 462,\n",
       " 'carrera': 156,\n",
       " 'actor': 48,\n",
       " 'director': 287,\n",
       " 'escritor': 342,\n",
       " 'decenas': 255,\n",
       " 'peliculas': 711,\n",
       " 'importantes': 476,\n",
       " 'historia': 453,\n",
       " 'cine': 174,\n",
       " 'humor': 464,\n",
       " 'mayoria': 584,\n",
       " 'encuentran': 324,\n",
       " 'publico': 799,\n",
       " 'online': 677,\n",
       " 'mejores': 590,\n",
       " 'museo': 630,\n",
       " 'finalmente': 397,\n",
       " 'siglo': 874,\n",
       " 'musica': 631,\n",
       " 'texto': 926,\n",
       " 'creado': 233,\n",
       " 'nombre': 651,\n",
       " 'obra': 663,\n",
       " 'video': 976,\n",
       " 'hombre': 456,\n",
       " 'comida': 190,\n",
       " 'muestra': 624,\n",
       " 'problema': 773,\n",
       " 'usando': 953,\n",
       " 'google': 432,\n",
       " 'dando': 248,\n",
       " 'mundo': 629,\n",
       " 'lugares': 555,\n",
       " 'alguien': 61,\n",
       " 'ordenador': 683,\n",
       " 'punto': 807,\n",
       " 'rusia': 848,\n",
       " 'norte': 654,\n",
       " 'curioso': 245,\n",
       " 'territorio': 924,\n",
       " 'america': 69,\n",
       " 'gracias': 433,\n",
       " 'empresas': 319,\n",
       " 'asociacion': 98,\n",
       " 'anuncio': 83,\n",
       " 'semana': 863,\n",
       " 'francia': 411,\n",
       " 'vida': 974,\n",
       " 'maquinas': 570,\n",
       " 'arqueologos': 91,\n",
       " 'descubierto': 271,\n",
       " 'prueba': 791,\n",
       " 'piedra': 730,\n",
       " 'media': 585,\n",
       " 'kilometros': 521,\n",
       " 'construir': 216,\n",
       " 'ano': 75,\n",
       " '600': 33,\n",
       " 'metros': 600,\n",
       " 'altura': 67,\n",
       " 'grande': 435,\n",
       " 'edad': 303,\n",
       " 'estructura': 362,\n",
       " 'artificial': 94,\n",
       " 'descubrimiento': 272,\n",
       " 'antiguo': 79,\n",
       " 'obras': 664,\n",
       " 'luz': 558,\n",
       " 'llevado': 547,\n",
       " 'cabo': 129,\n",
       " 'politicos': 745,\n",
       " 'dinero': 283,\n",
       " 'pequeno': 717,\n",
       " 'ocurre': 671,\n",
       " 'demuestra': 265,\n",
       " 'riesgo': 843,\n",
       " 'enfermedades': 328,\n",
       " 'personas': 726,\n",
       " 'peso': 728,\n",
       " 'normal': 653,\n",
       " 'debate': 251,\n",
       " 'torno': 934,\n",
       " 'idea': 466,\n",
       " 'decada': 253,\n",
       " 'importante': 475,\n",
       " 'vista': 983,\n",
       " 'salud': 851,\n",
       " 'publica': 793,\n",
       " 'unica': 946,\n",
       " 'ingles': 493,\n",
       " 'frances': 410,\n",
       " 'aleman': 59,\n",
       " 'ejemplos': 310,\n",
       " 'inicio': 494,\n",
       " 'espanola': 348,\n",
       " 'dejo': 262,\n",
       " 'contar': 219,\n",
       " 'vidas': 975,\n",
       " 'carga': 154,\n",
       " 'artistas': 96,\n",
       " 'especie': 352,\n",
       " 'evolucion': 374,\n",
       " 'seres': 868,\n",
       " 'humanos': 463,\n",
       " 'fuerza': 418,\n",
       " 'seleccion': 862,\n",
       " 'objetivo': 660,\n",
       " 'grupo': 436,\n",
       " 'web': 992,\n",
       " 'internet': 501,\n",
       " 'ultimos': 945,\n",
       " 'convertido': 224,\n",
       " 'millon': 607,\n",
       " 'euros': 371,\n",
       " 'modelo': 613,\n",
       " 'trafico': 939,\n",
       " 'razon': 815,\n",
       " 'ambiente': 68,\n",
       " 'ciencia': 169,\n",
       " 'medicos': 586,\n",
       " 'capaz': 150,\n",
       " 'calle': 133,\n",
       " 'familia': 388,\n",
       " 'resultados': 840,\n",
       " 'nino': 646,\n",
       " 'nivel': 648,\n",
       " '70': 34,\n",
       " 'nasa': 634,\n",
       " 'ordenadores': 684,\n",
       " 'ayuda': 111,\n",
       " 'origen': 686,\n",
       " 'investigador': 503,\n",
       " 'trabajando': 937,\n",
       " 'ideas': 467,\n",
       " 'teoria': 921,\n",
       " 'universidad': 951,\n",
       " 'relacionada': 831,\n",
       " 'contrario': 222,\n",
       " 'especies': 353,\n",
       " 'medida': 587,\n",
       " 'afecta': 52,\n",
       " 'cultura': 243,\n",
       " 'importancia': 474,\n",
       " 'figura': 395,\n",
       " 'republica': 832,\n",
       " 'fotos': 409,\n",
       " '2017': 19,\n",
       " 'ocurrio': 672,\n",
       " 'febrero': 391,\n",
       " 'tipo': 930,\n",
       " 'rio': 844,\n",
       " 'campana': 142,\n",
       " 'cuerpo': 241,\n",
       " 'diario': 277,\n",
       " 'iba': 465,\n",
       " 'viaje': 973,\n",
       " 'muerte': 622,\n",
       " 'par': 699,\n",
       " 'mapas': 568,\n",
       " 'zona': 998,\n",
       " 'espana': 346,\n",
       " 'armas': 90,\n",
       " 'acabar': 40,\n",
       " 'series': 871,\n",
       " 'orden': 682,\n",
       " 'calidad': 131,\n",
       " 'frente': 414,\n",
       " 'pantalla': 697,\n",
       " 'lineas': 535,\n",
       " 'codigo': 184,\n",
       " 'probable': 771,\n",
       " 'justo': 520,\n",
       " 'necesario': 640,\n",
       " 'fuente': 415,\n",
       " 'papel': 698,\n",
       " 'pueblo': 800,\n",
       " '12': 4,\n",
       " 'julio': 518,\n",
       " '000': 0,\n",
       " 'madrid': 560,\n",
       " 'buscar': 127,\n",
       " 'marzo': 576,\n",
       " '2016': 18,\n",
       " 'millones': 608,\n",
       " 'seguridad': 860,\n",
       " 'realmente': 819,\n",
       " 'meses': 597,\n",
       " 'septiembre': 867,\n",
       " '15': 7,\n",
       " 'publicada': 795,\n",
       " 'version': 971,\n",
       " 'exactamente': 375,\n",
       " 'provincia': 788,\n",
       " 'mujer': 626,\n",
       " 'pese': 727,\n",
       " '100': 2,\n",
       " 'habitantes': 440,\n",
       " 'llega': 542,\n",
       " 'ciudad': 175,\n",
       " 'pueblos': 801,\n",
       " '80': 35,\n",
       " 'servicios': 873,\n",
       " 'ciudades': 177,\n",
       " 'animal': 73,\n",
       " 'practicamente': 754,\n",
       " 'trabajadores': 936,\n",
       " 'empresa': 318,\n",
       " 'negocio': 642,\n",
       " 'mil': 604,\n",
       " 'ultima': 943,\n",
       " 'india': 483,\n",
       " 'presentado': 763,\n",
       " 'gobierno': 430,\n",
       " 'australia': 105,\n",
       " '11': 3,\n",
       " '14': 6,\n",
       " 'linux': 536,\n",
       " 'abierto': 37,\n",
       " 'edicion': 304,\n",
       " 'software': 891,\n",
       " 'libre': 531,\n",
       " 'creador': 234,\n",
       " 'control': 223,\n",
       " 'entrevista': 334,\n",
       " 'the': 927,\n",
       " 'ley': 529,\n",
       " 'consumo': 217,\n",
       " 'sol': 892,\n",
       " 'fuerte': 417,\n",
       " 'contiene': 221,\n",
       " 'cantidad': 147,\n",
       " 'ojos': 676,\n",
       " 'contenido': 220,\n",
       " 'puesto': 806,\n",
       " 'actualidad': 51,\n",
       " 'especialmente': 351,\n",
       " 'casos': 160,\n",
       " 'hijos': 452,\n",
       " 'programas': 784,\n",
       " 'atencion': 102,\n",
       " 'oceano': 669,\n",
       " 'mar': 571,\n",
       " 'costa': 230,\n",
       " 'realidad': 818,\n",
       " 'ocasiones': 668,\n",
       " 'conjunto': 205,\n",
       " 'construccion': 214,\n",
       " 'humana': 460,\n",
       " 'antigua': 77,\n",
       " 'europa': 368,\n",
       " 'situado': 887,\n",
       " 'titulo': 932,\n",
       " 'leer': 526,\n",
       " 'probablemente': 772,\n",
       " 'conocida': 207,\n",
       " 'vive': 985,\n",
       " 'actividad': 47,\n",
       " 'generar': 425,\n",
       " 'efecto': 308,\n",
       " 'cadena': 130,\n",
       " 'consecuencias': 211,\n",
       " 'acerca': 46,\n",
       " 'cambios': 140,\n",
       " 'profesor': 781,\n",
       " 'produce': 777,\n",
       " 'modelos': 614,\n",
       " 'aspecto': 99,\n",
       " 'tenia': 919,\n",
       " 'planeta': 734,\n",
       " 'futuro': 422,\n",
       " 'herramientas': 449,\n",
       " 'cambio': 139,\n",
       " 'social': 888,\n",
       " 'decadas': 254,\n",
       " 'viene': 979,\n",
       " 'duda': 301,\n",
       " 'acabo': 41,\n",
       " 'telescopio': 912,\n",
       " 'espacial': 344,\n",
       " 'equipo': 336,\n",
       " 'astronomos': 100,\n",
       " 'negro': 643,\n",
       " 'maximo': 581,\n",
       " 'temperatura': 916,\n",
       " 'atmosfera': 103,\n",
       " 'investigadores': 504,\n",
       " 'agua': 55,\n",
       " '400': 29,\n",
       " 'completo': 195,\n",
       " 'gas': 423,\n",
       " 'dificil': 281,\n",
       " 'resulta': 838,\n",
       " 'superficie': 903,\n",
       " 'deberia': 252,\n",
       " 'seria': 869,\n",
       " 'puntos': 808,\n",
       " 'distancia': 293,\n",
       " 'centro': 164,\n",
       " 'agosto': 54,\n",
       " 'francisco': 412,\n",
       " 'franco': 413,\n",
       " 'arte': 92,\n",
       " 'paso': 709,\n",
       " 'siglos': 875,\n",
       " 'propiedad': 785,\n",
       " 'gente': 427,\n",
       " 'utiliza': 956,\n",
       " 'incluyendo': 481,\n",
       " 'moviles': 620,\n",
       " 'traves': 941,\n",
       " 'marca': 572,\n",
       " 'historico': 455,\n",
       " 'problemas': 774,\n",
       " 'enfermedad': 327,\n",
       " 'acceder': 42,\n",
       " 'digital': 282,\n",
       " 'mala': 561,\n",
       " 'libros': 533,\n",
       " 'industria': 484,\n",
       " 'existencia': 376,\n",
       " 'libro': 532,\n",
       " 'venta': 967,\n",
       " 'britanica': 124,\n",
       " 'entorno': 331,\n",
       " 'oficial': 674,\n",
       " 'llego': 546,\n",
       " 'jueves': 517,\n",
       " 'investigacion': 502,\n",
       " 'servicio': 872,\n",
       " 'responsable': 833,\n",
       " 'comunicacion': 198,\n",
       " 'twitter': 942,\n",
       " 'encontrado': 320,\n",
       " 'imagenes': 471,\n",
       " 'termino': 922,\n",
       " 'nacional': 633,\n",
       " 'natural': 635,\n",
       " 'unidos': 949,\n",
       " 'local': 550,\n",
       " 'siquiera': 881,\n",
       " 'supone': 905,\n",
       " '60': 32,\n",
       " 'canada': 145,\n",
       " 'grupos': 437,\n",
       " 'palabras': 696,\n",
       " 'viernes': 980,\n",
       " 'encontrar': 321,\n",
       " 'ayuntamiento': 112,\n",
       " 'clave': 180,\n",
       " 'octubre': 670,\n",
       " 'pruebas': 792,\n",
       " '22': 21,\n",
       " '18': 10,\n",
       " 'tipos': 931,\n",
       " 'datos': 249,\n",
       " 'cientificos': 172,\n",
       " 'vuelta': 990,\n",
       " 'conocimiento': 210,\n",
       " 'produccion': 776,\n",
       " 'electrico': 314,\n",
       " 'york': 996,\n",
       " 'mes': 596,\n",
       " 'coche': 182,\n",
       " 'rapido': 814,\n",
       " 'velocidad': 965,\n",
       " 'cabeza': 128,\n",
       " 'naturaleza': 637,\n",
       " 'joven': 512,\n",
       " 'llamado': 540,\n",
       " 'instituto': 495,\n",
       " 'paris': 702,\n",
       " 'premio': 759,\n",
       " 'of': 673,\n",
       " 'londres': 553,\n",
       " 'fotografias': 407,\n",
       " 'alla': 64,\n",
       " 'carlos': 155,\n",
       " 'lunes': 557,\n",
       " 'popular': 747,\n",
       " 'serie': 870,\n",
       " 'mexico': 601,\n",
       " 'hechos': 447,\n",
       " 'documental': 299,\n",
       " 'numero': 659,\n",
       " 'significa': 876,\n",
       " 'concepto': 201,\n",
       " '500': 31,\n",
       " 'san': 852,\n",
       " 'estudios': 366,\n",
       " 'rey': 842,\n",
       " 'ii': 469,\n",
       " 'logrado': 551,\n",
       " '19': 11,\n",
       " '300': 26,\n",
       " 'cuya': 246,\n",
       " 'caracteristicas': 153,\n",
       " 'comun': 197,\n",
       " 'estilo': 359,\n",
       " 'coleccion': 186,\n",
       " 'videojuegos': 977,\n",
       " 'noche': 650,\n",
       " 'diciembre': 278,\n",
       " 'dejado': 260,\n",
       " 'practica': 753,\n",
       " 'presencia': 761,\n",
       " 'accion': 45,\n",
       " 'actual': 49,\n",
       " 'situacion': 886,\n",
       " 'plan': 733,\n",
       " 'ciudadanos': 176,\n",
       " 'desarrollo': 270,\n",
       " 'opinion': 679,\n",
       " 'comunicado': 199,\n",
       " 'puedes': 803,\n",
       " 'carta': 157,\n",
       " 'jamas': 507,\n",
       " '20': 12,\n",
       " 'profundidad': 782,\n",
       " 'entrada': 332,\n",
       " 'camara': 136,\n",
       " 'verano': 968,\n",
       " 'noticia': 655,\n",
       " 'espacio': 345,\n",
       " 'partido': 706,\n",
       " 'puerta': 804,\n",
       " 'sitios': 885,\n",
       " 'encontro': 323,\n",
       " 'junio': 519,\n",
       " 'cambiar': 138,\n",
       " 'decidio': 257,\n",
       " 'utilizan': 958,\n",
       " 'productos': 780,\n",
       " 'funcionamiento': 421,\n",
       " 'universo': 952,\n",
       " '40': 28,\n",
       " 'hora': 458,\n",
       " '50': 30,\n",
       " 'cuestion': 242,\n",
       " 'hallazgo': 446,\n",
       " 'desarrollar': 269,\n",
       " 'espera': 355,\n",
       " 'herramienta': 448,\n",
       " 'lucha': 554,\n",
       " 'cancer': 146,\n",
       " 'explica': 381,\n",
       " 'inglaterra': 492,\n",
       " 'escrito': 341,\n",
       " 'redes': 826,\n",
       " 'imperio': 473,\n",
       " 'mensaje': 593,\n",
       " 'deja': 259,\n",
       " 'proceso': 775,\n",
       " 'recientemente': 822,\n",
       " 'restos': 837,\n",
       " 'ejercito': 311,\n",
       " 'evitar': 373,\n",
       " 'increible': 482,\n",
       " 'llamada': 539,\n",
       " 'marcha': 573,\n",
       " 'alemania': 60,\n",
       " 'estacion': 356,\n",
       " 'coches': 183,\n",
       " 'electricos': 315,\n",
       " 'trabajos': 938,\n",
       " 'responsables': 834,\n",
       " 'pelicula': 710,\n",
       " 'casa': 158,\n",
       " 'mano': 564,\n",
       " 'materiales': 580,\n",
       " 'arboles': 88,\n",
       " 'hombres': 457,\n",
       " 'enero': 326,\n",
       " 'luna': 556,\n",
       " 'protagonista': 786,\n",
       " 'xx': 995,\n",
       " 'fisica': 398,\n",
       " 'famosa': 389,\n",
       " 'especial': 350,\n",
       " 'principio': 769,\n",
       " 'hablamos': 442,\n",
       " 'anunciado': 82,\n",
       " 'ee': 306,\n",
       " 'conocido': 208,\n",
       " 'utilizado': 957,\n",
       " 'companias': 192,\n",
       " 'red': 825,\n",
       " 'tecnologia': 910,\n",
       " 'llegado': 544,\n",
       " 'metro': 599,\n",
       " 'dejar': 261,\n",
       " 'comunidad': 200,\n",
       " 'calles': 134,\n",
       " 'miembros': 603,\n",
       " 'publicar': 797,\n",
       " 'proteccion': 787,\n",
       " 'acceso': 43,\n",
       " 'decision': 258,\n",
       " 'parque': 703,\n",
       " 'isla': 505,\n",
       " 'creen': 238,\n",
       " 'visto': 984,\n",
       " 'habian': 439,\n",
       " 'superior': 904,\n",
       " 'resto': 836,\n",
       " 'guerra': 438,\n",
       " 'mundial': 628,\n",
       " 'japon': 508,\n",
       " 'ministerio': 609,\n",
       " 'europeo': 370,\n",
       " 'acaba': 39,\n",
       " 'programa': 783,\n",
       " 'usuarios': 955,\n",
       " 'disponible': 290,\n",
       " 'pagina': 692,\n",
       " 'destino': 275,\n",
       " 'blog': 123,\n",
       " 'cientifico': 171,\n",
       " 'desarrollado': 268,\n",
       " 'generacion': 424,\n",
       " 'permite': 722,\n",
       " 'pequenas': 716,\n",
       " 'real': 817,\n",
       " 'animales': 74,\n",
       " 'imagen': 470,\n",
       " 'manos': 565,\n",
       " 'llama': 538,\n",
       " 'partes': 704,\n",
       " 'caso': 159,\n",
       " 'aire': 57,\n",
       " 'plantas': 736,\n",
       " 'energia': 325,\n",
       " 'solar': 893,\n",
       " 'producir': 778,\n",
       " 'electricidad': 313,\n",
       " 'record': 823,\n",
       " 'capacidad': 149,\n",
       " 'nuclear': 658,\n",
       " 'civil': 178,\n",
       " 'compania': 191,\n",
       " 'aplicacion': 85,\n",
       " '10': 1,\n",
       " 'larga': 525,\n",
       " 'piezas': 732,\n",
       " 'peligro': 712,\n",
       " 'vehiculos': 964,\n",
       " 'crear': 235,\n",
       " 'momentos': 615,\n",
       " 'artista': 95,\n",
       " 'sector': 856,\n",
       " 'actuales': 50,\n",
       " 'paises': 694,\n",
       " 'revista': 841,\n",
       " 'cientifica': 170,\n",
       " 'expertos': 380,\n",
       " 'articulo': 93,\n",
       " 'unico': 947,\n",
       " 'capaces': 148,\n",
       " 'sistemas': 883,\n",
       " 'siguen': 877,\n",
       " 'material': 579,\n",
       " 'contacto': 218,\n",
       " 'sociedad': 890,\n",
       " 'persona': 723,\n",
       " 'algun': 62,\n",
       " 'rojo': 846,\n",
       " 'dios': 284,\n",
       " 'precio': 755,\n",
       " 'memoria': 591,\n",
       " 'sentido': 866,\n",
       " 'satelite': 854,\n",
       " 'pequena': 715,\n",
       " 'suficiente': 902,\n",
       " 'region': 828,\n",
       " 'periodo': 721,\n",
       " 'diseno': 289,\n",
       " 'primeras': 766,\n",
       " 'vineta': 981,\n",
       " 'ficcion': 394,\n",
       " 'experimento': 379,\n",
       " 'diversas': 297,\n",
       " 'parecer': 701,\n",
       " 'xix': 994,\n",
       " 'madre': 559,\n",
       " 'fuentes': 416,\n",
       " 'salir': 850,\n",
       " 'plataforma': 737,\n",
       " 'objetos': 662,\n",
       " 'marte': 574,\n",
       " 'formacion': 403,\n",
       " 'falta': 387,\n",
       " 'descubrir': 274,\n",
       " 'podia': 740,\n",
       " 'original': 687,\n",
       " 'incluye': 480,\n",
       " 'escribir': 340,\n",
       " 'agencia': 53,\n",
       " 'km': 522,\n",
       " 'segundos': 858,\n",
       " 'seguir': 857,\n",
       " 'android': 72,\n",
       " 'gigante': 428,\n",
       " 'cuyo': 247,\n",
       " 'posibilidad': 749,\n",
       " '200': 13,\n",
       " 'economico': 302,\n",
       " 'militar': 606,\n",
       " 'mision': 611,\n",
       " 'campo': 143,\n",
       " 'batalla': 119,\n",
       " 'oro': 688,\n",
       " 'estrella': 360,\n",
       " 'tecnicas': 909,\n",
       " 'fotografia': 406,\n",
       " 'camaras': 137,\n",
       " 'tenian': 920,\n",
       " 'vehiculo': 963,\n",
       " 'antiguedad': 78,\n",
       " 'crecimiento': 236,\n",
       " 'cerebro': 165,\n",
       " 'tamano': 907,\n",
       " 'pequenos': 718,\n",
       " 'obtener': 666,\n",
       " 'television': 913,\n",
       " 'jefe': 509,\n",
       " 'llamar': 541,\n",
       " 'derechos': 267,\n",
       " 'autor': 106,\n",
       " 'informe': 488,\n",
       " 'muestran': 625,\n",
       " 'evidencia': 372,\n",
       " 'linea': 534,\n",
       " 'ningun': 645,\n",
       " 'noticias': 656,\n",
       " 'solucion': 894,\n",
       " 'nacio': 632,\n",
       " 'interior': 499,\n",
       " 'muerto': 623,\n",
       " 'causa': 161,\n",
       " 'ultimas': 944,\n",
       " '23': 22,\n",
       " 'cultural': 244,\n",
       " 'jovenes': 513,\n",
       " 'busca': 126,\n",
       " 'informacion': 486,\n",
       " 'microsoft': 602,\n",
       " 'facebook': 385,\n",
       " 'funciona': 420,\n",
       " 'disenado': 288,\n",
       " 'nave': 638,\n",
       " 'condiciones': 203,\n",
       " 'david': 250,\n",
       " 'famoso': 390,\n",
       " 'reciente': 821,\n",
       " 'respuesta': 835,\n",
       " 'navegador': 639,\n",
       " 'conoce': 206,\n",
       " 'vemos': 966,\n",
       " 'demas': 263,\n",
       " 'aplicaciones': 86,\n",
       " 'perdida': 719,\n",
       " 'hablar': 443,\n",
       " 'suelen': 899,\n",
       " 'distintos': 295,\n",
       " 'uu': 961,\n",
       " 'diferencia': 280,\n",
       " '90': 36,\n",
       " 'vuelve': 991,\n",
       " 'minutos': 610,\n",
       " 'california': 132,\n",
       " 'interesante': 498,\n",
       " 'semanas': 864,\n",
       " 'informatica': 487,\n",
       " 'fenomeno': 393,\n",
       " 'educacion': 305,\n",
       " 'fecha': 392,\n",
       " 'banda': 115,\n",
       " 'personajes': 724,\n",
       " 'calor': 135,\n",
       " 'suelo': 900,\n",
       " 'estadounidense': 357,\n",
       " 'poblacion': 739,\n",
       " 'relacion': 830,\n",
       " 'principios': 770,\n",
       " 'particulas': 705,\n",
       " 'alta': 65,\n",
       " 'temperaturas': 917,\n",
       " 'directamente': 286,\n",
       " 'fotografo': 408,\n",
       " 'ingeniero': 490,\n",
       " 'movimiento': 621,\n",
       " 'finales': 396,\n",
       " 'tecnica': 908,\n",
       " 'cien': 168,\n",
       " '2015': 17,\n",
       " 'humanidad': 461,\n",
       " 'razones': 816,\n",
       " 'aviones': 110,\n",
       " 'cielo': 167,\n",
       " 'explicacion': 382,\n",
       " 'motivo': 617,\n",
       " 'capital': 151,\n",
       " 'golpe': 431,\n",
       " 'explicar': 383,\n",
       " 'perdido': 720,\n",
       " 'mayores': 583,\n",
       " 'distribucion': 296,\n",
       " 'efectos': 309,\n",
       " 'decidido': 256,\n",
       " 'recursos': 824,\n",
       " 'juegos': 516,\n",
       " 'miles': 605,\n",
       " 'compartir': 193,\n",
       " 'sociales': 889,\n",
       " 'mercado': 595,\n",
       " 'apple': 87,\n",
       " 'autores': 107,\n",
       " 'publicacion': 794,\n",
       " 'ocasion': 667,\n",
       " 'aguas': 56,\n",
       " 'policia': 743,\n",
       " 'cientos': 173,\n",
       " 'habria': 445,\n",
       " 'impresionante': 478,\n",
       " 'comenzo': 189,\n",
       " 'blanco': 122,\n",
       " 'global': 429,\n",
       " 'volver': 987,\n",
       " 'padre': 689,\n",
       " 'accidente': 44,\n",
       " 'dolares': 300,\n",
       " 'baja': 114,\n",
       " 'pagar': 691,\n",
       " 'direccion': 285,\n",
       " 'telefono': 911,\n",
       " 'suele': 898,\n",
       " 'concreto': 202,\n",
       " 'principales': 768,\n",
       " 'dispositivo': 291,\n",
       " 'corazon': 228,\n",
       " 'operativo': 678,\n",
       " 'windows': 993,\n",
       " 'usuario': 954,\n",
       " 'tendra': 918,\n",
       " 'base': 118,\n",
       " 'manana': 562,\n",
       " 'completamente': 194,\n",
       " 'sonda': 895,\n",
       " 'abril': 38,\n",
       " 'detalles': 276,\n",
       " 'genero': 426,\n",
       " 'ofrece': 675,\n",
       " 'observar': 665,\n",
       " 'habra': 444,\n",
       " 'rajoy': 813,\n",
       " 'radio': 812,\n",
       " 'in': 479,\n",
       " 'ninos': 647,\n",
       " 'mostrar': 616,\n",
       " 'piel': 731,\n",
       " '2013': 15,\n",
       " 'aparece': 84,\n",
       " 'polemica': 742,\n",
       " 'llegada': 543,\n",
       " 'impacto': 472,\n",
       " 'voz': 988,\n",
       " 'tiempos': 928,\n",
       " 'alto': 66,\n",
       " 'utilizando': 959,\n",
       " 'publicidad': 798,\n",
       " 'posicion': 750,\n",
       " 'motor': 618,\n",
       " 'necesidad': 641,\n",
       " 'planetas': 735,\n",
       " 'suerte': 901,\n",
       " 'mayo': 582,\n",
       " 'reino': 829,\n",
       " 'unido': 948,\n",
       " 'mapa': 567,\n",
       " 'enorme': 329,\n",
       " 'new': 644,\n",
       " 'pluton': 738,\n",
       " 'area': 89,\n",
       " 'orbita': 681,\n",
       " 'mujeres': 627,\n",
       " 'organizacion': 685,\n",
       " 'masa': 577,\n",
       " 'cree': 237,\n",
       " 'manel': 563,\n",
       " 'fontdevila': 401,\n",
       " 'llevan': 548,\n",
       " 'foto': 405,\n",
       " 'sorprendente': 896,\n",
       " 'funcion': 419,\n",
       " 'vivir': 986,\n",
       " 'post': 751,\n",
       " 'campos': 144,\n",
       " '16': 8,\n",
       " 'sorpresa': 897,\n",
       " 'estadounidenses': 358,\n",
       " 'producto': 779,\n",
       " 'tesla': 925,\n",
       " 'experiencia': 378,\n",
       " 'derecho': 266,\n",
       " 'presente': 764,\n",
       " 'estudiar': 364,\n",
       " 'juego': 515,\n",
       " 'pasa': 707,\n",
       " 'extrano': 384,\n",
       " 'medios': 588,\n",
       " 'cualquiera': 240,\n",
       " 'tema': 914,\n",
       " '2012': 14,\n",
       " 'queda': 810,\n",
       " 'bernardo': 121,\n",
       " 'vergara': 970,\n",
       " 'seguro': 861,\n",
       " 'clase': 179,\n",
       " 'movil': 619,\n",
       " 'precisamente': 756,\n",
       " 'similar': 878,\n",
       " 'utilizar': 960,\n",
       " 'mejorar': 589,\n",
       " 'parecen': 700,\n",
       " 've': 962,\n",
       " 'facil': 386,\n",
       " 'imposible': 477,\n",
       " 'convierte': 226,\n",
       " 'sur': 906,\n",
       " 'central': 163,\n",
       " '3d': 27,\n",
       " 'celulas': 162,\n",
       " 'lista': 537,\n",
       " 'resultado': 839,\n",
       " 'interes': 497,\n",
       " '13': 5,\n",
       " 'amigos': 70,\n",
       " 'empezo': 317,\n",
       " 'antiguos': 80,\n",
       " 'diez': 279,\n",
       " 'camino': 141,\n",
       " 'tomar': 933,\n",
       " 'clientes': 181,\n",
       " 'habitual': 441,\n",
       " 'padres': 690,\n",
       " 'puso': 809,\n",
       " 'azul': 113,\n",
       " 'vuelo': 989,\n",
       " 'jose': 511,\n",
       " 'vision': 982,\n",
       " 'menor': 592,\n",
       " 'zonas': 999,\n",
       " 'fondo': 400,\n",
       " 'convertirse': 225,\n",
       " 'llegar': 545,\n",
       " '25': 24,\n",
       " 'libertad': 530,\n",
       " 'pp': 752,\n",
       " 'diversos': 298,\n",
       " 'john': 510,\n",
       " 'prensa': 760,\n",
       " 'creacion': 232,\n",
       " 'romano': 847,\n",
       " 'peninsula': 713,\n",
       " 'cara': 152,\n",
       " 'industrial': 485,\n",
       " 'baterias': 120,\n",
       " 'barcelona': 116,\n",
       " 'martin': 575,\n",
       " 'dispositivos': 292,\n",
       " 'ataque': 101,\n",
       " 'alimentos': 63,\n",
       " 'proyectos': 790,\n",
       " 'via': 972,\n",
       " 'lenguaje': 528,\n",
       " 'mente': 594,\n",
       " 'descubrio': 273,\n",
       " 'podido': 741,\n",
       " 'ruso': 849,\n",
       " 'conseguido': 212,\n",
       " 'analisis': 71,\n",
       " 'simple': 879,\n",
       " 'escena': 339,\n",
       " 'videos': 978,\n",
       " 'fisico': 399,\n",
       " 'youtube': 997,\n",
       " 'formas': 404,\n",
       " 'ido': 468,\n",
       " 'asegura': 97,\n",
       " 'pone': 746,\n",
       " 'inteligencia': 496,\n",
       " 'colores': 188,\n",
       " 'cosa': 229,\n",
       " 'preguntas': 758,\n",
       " 'materia': 578,\n",
       " '17': 9,\n",
       " 'paginas': 693,\n",
       " 'convirtio': 227,\n",
       " 'eeuu': 307,\n",
       " 'pie': 729,\n",
       " 'cohete': 185,\n",
       " 'escala': 338,\n",
       " 'avion': 109,\n",
       " '21': 20,\n",
       " 'oportunidad': 680,\n",
       " 'coste': 231,\n",
       " 'alcanzar': 58,\n",
       " 'estrellas': 361,\n",
       " 'estudiantes': 363,\n",
       " 'britanico': 125,\n",
       " 'etc': 367,\n",
       " 'sencilla': 865,\n",
       " 'palabra': 695,\n",
       " 'mantener': 566,\n",
       " 'demostrado': 264,\n",
       " 'crisis': 239,\n",
       " 'seguramente': 859,\n",
       " '2014': 16,\n",
       " '24': 23,\n",
       " 'islas': 506,\n",
       " 'nombres': 652,\n",
       " 'naturales': 636,\n",
       " 'juan': 514,\n",
       " 'puerto': 805,\n",
       " 'temas': 915,\n",
       " 'distintas': 294,\n",
       " 'color': 187,\n",
       " 'pregunta': 757,\n",
       " 'historias': 454,\n",
       " 'presidente': 765,\n",
       " 'mitad': 612,\n",
       " 'lanzamiento': 524,\n",
       " 'construido': 215,\n",
       " 'autoridades': 108,\n",
       " 'electrica': 312,\n",
       " 'presenta': 762,\n",
       " 'llevo': 549,\n",
       " 'conocidos': 209,\n",
       " 'politica': 744,\n",
       " 'ingenieros': 491,\n",
       " 'aumento': 104,\n",
       " 'niveles': 649,\n",
       " 'hospital': 459,\n",
       " 'grafico': 434,\n",
       " 'comportamiento': 196,\n",
       " 'noviembre': 657,\n",
       " 'antonio': 81,\n",
       " 'elementos': 316,\n",
       " 'entrar': 333,\n",
       " 'pensar': 714,\n",
       " 'maquina': 569,\n",
       " 'quieren': 811,\n",
       " 'transporte': 940,\n",
       " 'barco': 117,\n",
       " 'terreno': 923,\n",
       " 'error': 337,\n",
       " 'populares': 748,\n",
       " 'laboratorio': 523,\n",
       " 'sitio': 884,\n",
       " 'objeto': 661,\n",
       " 'escuela': 343,\n",
       " 'recibido': 820,\n",
       " 'simplemente': 880,\n",
       " 'hielo': 450,\n",
       " 'espectacular': 354,\n",
       " 'encontraron': 322,\n",
       " 'ingenieria': 489,\n",
       " 'hijo': 451,\n",
       " 'secreto': 855,\n",
       " 'reducir': 827,\n",
       " 'sangre': 853,\n",
       " 'considerado': 213}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_cuenta.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=vectorizador_cuenta.fit_transform(noticias.descripcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo=BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(vector.toarray(),noticias.categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion=modelo.predict(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cultura', 'cultura', 'tecnología', ..., 'tecnología', 'cultura',\n",
       "       'cultura'], dtype='<U10')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           cultura\n",
       "1           cultura\n",
       "2        tecnología\n",
       "3           cultura\n",
       "4           cultura\n",
       "            ...    \n",
       "16490          ocio\n",
       "16491       cultura\n",
       "16492       cultura\n",
       "16493    tecnología\n",
       "16494          ocio\n",
       "Name: categoria, Length: 16495, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias.categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
